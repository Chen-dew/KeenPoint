"""
æµ‹è¯• NLP Service çš„ç« èŠ‚åˆ†æåŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.services.parse_service import parse_markdown_file
from app.services.nlp_service import extract_and_split_sections, analyze_segments_with_abstract
import json


def test_segment_analysis():
    """æµ‹è¯•ç« èŠ‚åˆ†æåŠŸèƒ½"""
    
    print("=" * 80)
    print("NLP Service - ç« èŠ‚åˆ†æåŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    print()
    
    # æµ‹è¯•æ–‡ä»¶è·¯å¾„
    test_md_files = [
        r"D:\MyFiles\AIPPT\Code\keenPoint\downloads\Lin_HRank_Filter_Pruning_Using_High-Rank_Feature_Map_CVPR_2020_paper\full.md"
    ]
    
    md_file = None
    for test_file in test_md_files:
        if Path(test_file).exists():
            md_file = test_file
            break
    
    if not md_file:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯• Markdown æ–‡ä»¶")
        print("è¯·åˆ›å»ºæµ‹è¯•æ–‡ä»¶æˆ–ä¿®æ”¹ test_md_files åˆ—è¡¨")
        return
    
    print(f"ğŸ“„ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {md_file}")
    print()
    
    try:
        # æ­¥éª¤ 1: è§£æ Markdown æ–‡ä»¶
        print("æ­¥éª¤ 1: è§£æ Markdown æ–‡ä»¶...")
        parse_result = parse_markdown_file(md_file)
        sections = parse_result.get("sections", [])
        print(f"âœ… è§£æå®Œæˆï¼Œå…± {len(sections)} ä¸ªç« èŠ‚")
        print()
        
        # æ­¥éª¤ 2: æå–æ‘˜è¦
        print("æ­¥éª¤ 2: æå–è®ºæ–‡æ‘˜è¦...")
        abstract = ""
        for section in sections:
            name = section.get("name", "").lower()
            if "abstract" in name or "æ‘˜è¦" in section.get("name", ""):
                abstract = section.get("content", "")
                print(f"âœ… æ‰¾åˆ°æ‘˜è¦ç« èŠ‚: {section.get('name')}")
                print(f"   æ‘˜è¦é•¿åº¦: {len(abstract)} å­—ç¬¦")
                break
        
        if not abstract:
            print("âš ï¸  æœªæ‰¾åˆ°æ‘˜è¦ç« èŠ‚ï¼Œä½¿ç”¨ç©ºæ‘˜è¦")
            abstract = "No abstract available."
        print()
        
        # æ­¥éª¤ 3: æå–å¹¶æ‹†åˆ†ç« èŠ‚
        print("æ­¥éª¤ 3: æå–å¹¶æ‹†åˆ†ç« èŠ‚...")
        segments = extract_and_split_sections(parse_result)
        print(f"âœ… æ‹†åˆ†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(segments)} ä¸ªç‰‡æ®µ")
        
        # æ˜¾ç¤ºæ‹†åˆ†ä¿¡æ¯
        split_sections = {}
        for seg in segments:
            if seg.get('is_split'):
                idx = seg.get('original_section_index')
                if idx not in split_sections:
                    split_sections[idx] = []
                split_sections[idx].append(seg)
        
        if split_sections:
            print(f"   å…¶ä¸­ {len(split_sections)} ä¸ªç« èŠ‚è¢«æ‹†åˆ†:")
            for idx, parts in split_sections.items():
                print(f"     - ç« èŠ‚ {idx}: æ‹†åˆ†ä¸º {len(parts)} ä¸ªéƒ¨åˆ†")
        print()
        
        # æ­¥éª¤ 4: ä½¿ç”¨ NLP æ¨¡å‹åˆ†æç« èŠ‚
        print("æ­¥éª¤ 4: ä½¿ç”¨ NLP æ¨¡å‹åˆ†æç« èŠ‚...")
        print("â³ æ­£åœ¨è°ƒç”¨ NLP APIï¼ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰...")
        print("ğŸ“Œ æ³¨æ„: æ‹†åˆ†ç« èŠ‚çš„åç»­éƒ¨åˆ†ä¼šåˆ©ç”¨å‰é¢éƒ¨åˆ†çš„åˆ†æç»“æœ")
        print("-" * 80)
        
        # åˆ†ææ‰€æœ‰ç‰‡æ®µ
        print(f"ğŸ“Š å°†åˆ†æå…¨éƒ¨ {len(segments)} ä¸ªç‰‡æ®µ")
        print()
        
        analysis_results = analyze_segments_with_abstract(
            segments=segments,
            abstract=abstract,
            skip_abstract_section=True
        )
        
        print()
        print(f"âœ… åˆ†æå®Œæˆï¼Œå…± {len(analysis_results)} ä¸ªç»“æœ")
        print()
        
        # æ­¥éª¤ 5: æ˜¾ç¤ºåˆ†æç»“æœ
        print("æ­¥éª¤ 5: åˆ†æç»“æœè¯¦æƒ…")
        print("=" * 80)
        
        for i, result in enumerate(analysis_results, 1):
            print(f"\n[ç»“æœ {i}]")
            print(f"ID: {result.get('id')}")
            print(f"ç« èŠ‚åç§°: {result.get('section_name')}")
            
            # å¦‚æœæœ‰å‰é¢éƒ¨åˆ†çš„æ‘˜è¦ï¼Œæ˜¾ç¤º
            if result.get('previous_part_summary'):
                print(f"\nğŸ“‹ å‰é¢éƒ¨åˆ†çš„æ‘˜è¦:")
                prev_summary = result.get('previous_part_summary', '')
                if len(prev_summary) > 200:
                    print(f"  {prev_summary[:200]}...")
                else:
                    print(f"  {prev_summary}")
            
            print(f"\næ‘˜è¦:")
            summary = result.get('summary', '')
            if len(summary) > 300:
                print(f"  {summary[:300]}...")
            else:
                print(f"  {summary}")
            
            key_points = result.get('key_points', [])
            if key_points:
                print(f"\nå…³é”®è¦ç‚¹ ({len(key_points)} ä¸ª):")
                for idx, point in enumerate(key_points, 1):
                    print(f"  {idx}. {point}")
            else:
                print("\nå…³é”®è¦ç‚¹: (æ— )")
            
            if result.get('error'):
                print(f"\nâš ï¸  é”™è¯¯: {result['error']}")
            
            print("-" * 80)
        
        # æ­¥éª¤ 6: ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶
        output_file = project_root / "test_analysis_output.json"
        print()
        print("æ­¥éª¤ 6: ä¿å­˜ç»“æœåˆ°æ–‡ä»¶")
        print("-" * 80)
        
        output_data = {
            "abstract": abstract[:500] + "..." if len(abstract) > 500 else abstract,
            "total_segments": len(segments),
            "analyzed_segments": len(analysis_results),
            "results": analysis_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    try:
        test_segment_analysis()
        
        print()
        print("=" * 80)
        print("âœ… æµ‹è¯•å®Œæˆ")
        print("=" * 80)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print("\næŒ‰ä»»æ„é”®é€€å‡º...")
    input()
